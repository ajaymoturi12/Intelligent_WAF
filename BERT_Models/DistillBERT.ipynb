{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":283,"status":"ok","timestamp":1714147274869,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"XFbiyvdlGN9u"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset, RandomSampler\n","\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","import random"]},{"cell_type":"markdown","metadata":{"id":"tYR1S8cqKNLm"},"source":["# CSIC and Vocab Classes"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11827,"status":"ok","timestamp":1714147249649,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"S65-90NlKMll"},"outputs":[],"source":["import os\n","from typing import List\n","from collections import Counter\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","\n","from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import ByteLevel\n","\n","from urllib import parse\n","\n","class CSICDataset(Dataset):\n","    def __init__(self, df: pd.DataFrame, vocab=None, vocab_size=1000, min_frequency=1, special_tokens=[\"[UNK]\",\"[CLS]\",\"[PAD]\"], tokenization_algorithm=\"bpe\"):\n","        self.df = df\n","\n","        # Export text content to csv for learning tokenization; apply BPE\n","        path = os.path.join('.', 'tokenization_input')\n","\n","        self.df.to_csv(path_or_buf=path, columns=['content_for_tokenization'], index=False, header=False)\n","\n","        if vocab == None:\n","            vocab = Vocab(vocab_size=vocab_size, min_frequency=min_frequency,\n","                           special_tokens=special_tokens,\n","                           tokenization_algorithm=tokenization_algorithm)\n","            vocab.build(corpus_files=[path])\n","\n","        self.vocab = vocab\n","\n","        self.encode_df()\n","\n","\n","    @staticmethod\n","    def process_df(df: pd.DataFrame):\n","        # Pre-process data by dropping rows without POST-Data or GET-Query\n","        get_mask, post_mask = df['GET-Query'].notna(), df['POST-Data'].notna()\n","\n","        df.loc[get_mask,\"content_for_tokenization\"] = df.loc[get_mask,\"GET-Query\"]\n","        df.loc[post_mask,\"content_for_tokenization\"] = df.loc[post_mask,\"POST-Data\"]\n","\n","        df = df[get_mask | post_mask]\n","        df = df.drop(columns=[\"GET-Query\",\"POST-Data\", \"Accept-Charset\", \"Accept-Language\", \"Accept\", \"Cache-control\", \"Pragma\", \"Content-Type\", \"Host-Header\", \"Connection\"])\n","\n","        return df\n","\n","    def encode_df(self):\n","        # Tokenize the GET-Query and POST-Data columns according to the subword vocabulary learned from BPE\n","        self.df[\"tokenized_ids\"] = self.df[\"content_for_tokenization\"].apply(lambda x: self.vocab.words2indices(x))\n","        self.df[\"tokenized\"] = self.df[\"content_for_tokenization\"].apply(lambda x: self.vocab.tokenize(x))\n","        self.df = self.df.drop(columns=[\"content_for_tokenization\"])\n","\n","        self.class_encoder, self.method_encoder = LabelEncoder(), LabelEncoder()\n","        self.df['Class'], self.df['Method'] = self.class_encoder.fit_transform(self.df['Class']), self.class_encoder.fit_transform(self.df['Method'])\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        features = self.df.iloc[index].drop(['Class', 'User-Agent'])\n","        label = self.df.iloc[index]['Class']\n","\n","        return features, label"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":193,"status":"ok","timestamp":1714147249840,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"-Rj6eSuvKWg_"},"outputs":[],"source":["class Vocab(object):\n","    def __init__(self, vocab_size=0, min_frequency=0, special_tokens: List[str]=[], unk_token=\"[UNK]\", pad_token=\"[PAD]\", tokenizer=None, tokenization_algorithm=\"bpe\"):\n","        if tokenizer:\n","            self.tokenizer = tokenizer\n","\n","            self.word2id = tokenizer.get_vocab()\n","            self.id2word = {v: k for k, v in self.word2id.items()}\n","\n","            self.unk_id = self.word2id[unk_token]\n","\n","        else:\n","            assert vocab_size > 0\n","            assert min_frequency > 0\n","\n","            self.vocab_size = vocab_size\n","            self.min_frequency = min_frequency\n","            self.special_tokens = special_tokens\n","            self.unk_token = unk_token\n","            self.pad_token = pad_token\n","            self.tokenization_algorithm = tokenization_algorithm\n","\n","    def build(self, corpus_files: List[str]):\n","        if self.tokenization_algorithm == 'bpe':\n","            tokenizer = Tokenizer(BPE(unk_token=self.unk_token))\n","            trainer = BpeTrainer(vocab_size=self.vocab_size, min_frequency=self.min_frequency, special_tokens=self.special_tokens)\n","            tokenizer.pre_tokenizer = ByteLevel()\n","\n","            tokenizer.train(corpus_files, trainer)\n","\n","            self.tokenizer = tokenizer\n","            self.word2id = tokenizer.get_vocab()\n","            self.id2word = {v: k for k, v in self.word2id.items()}\n","\n","        elif self.tokenization_algorithm == 'vocab_map':\n","            self.word2id, self.id2word = dict(), dict()\n","            curr_id, self.min_frequency = 1,1\n","            counter = Counter()\n","\n","            def add_to_vocab(token: str, ignore_cutoff=False):\n","                nonlocal curr_id\n","                if (ignore_cutoff or counter[token] >= self.min_frequency) and token not in self.word2id:\n","                    self.word2id[token] = curr_id\n","                    self.id2word[curr_id] = token\n","\n","                    curr_id += 1\n","\n","            for file_path in corpus_files:\n","                with open(file_path, 'r') as file:\n","                    for line in file:\n","                        tokens = Vocab.parse_req_body_or_params(line)\n","                        counter.update(tokens)\n","\n","            unwanted_tokens = [' ','']\n","            for token in unwanted_tokens:\n","                if token in counter:\n","                    del counter[token]\n","\n","            for token in self.special_tokens:\n","                add_to_vocab(token, ignore_cutoff=True)\n","\n","            for token in set(counter.elements()):\n","                add_to_vocab(token)\n","\n","        else:\n","            raise TypeError(\"Unsupported tokenization algorithm detected\")\n","\n","        self.unk_id = self.word2id[self.unk_token]\n","        self.pad_id = self.word2id[self.pad_token]\n","\n","    def __getitem__(self, word):\n","        return self.word2id.get(word, self.unk_id)\n","\n","    def __contains__(self, word):\n","        return word in self.word2id\n","\n","    def __setitem__(self, key, value):\n","        raise ValueError('vocabulary is readonly')\n","\n","    def __len__(self):\n","        return len(self.word2id)\n","\n","    def __repr__(self):\n","        return 'Vocabulary[size=%d]' % len(self)\n","\n","    def id2word(self, wid):\n","        return self.id2word[wid]\n","\n","    def save(self, file_path):\n","        self.tokenizer.save(path=file_path)\n","\n","    def words2indices(self, content):\n","        if self.tokenization_algorithm == 'bpe':\n","            if type(content) == list:\n","                return [self.tokenizer.encode(row).ids for row in content]\n","            else:\n","                return self.tokenizer.encode(content).ids\n","\n","        elif self.tokenization_algorithm == 'vocab_map':\n","            if type(content) == list:\n","                return [[self[token] for token in Vocab.parse_req_body_or_params(line)] for line in content]\n","            else:\n","                return [self[token] for token in Vocab.parse_req_body_or_params(content)]\n","        else:\n","            raise TypeError(\"Unsupported tokenization algorithm detected\")\n","\n","    def tokenize(self, content):\n","        if self.tokenization_algorithm == 'bpe':\n","            if type(content) == list:\n","                return [self.tokenizer.encode(row).tokens for row in content]\n","            else:\n","                return self.tokenizer.encode(content).tokens\n","\n","        elif self.tokenization_algorithm == 'vocab_map':\n","            if type(content) == list:\n","                return [[token if self.__contains__(token) else self.unk_token for token in Vocab.parse_req_body_or_params(line)] for line in content]\n","            else:\n","                return [token if self.__contains__(token) else self.unk_token for token in Vocab.parse_req_body_or_params(content)]\n","\n","        else:\n","            raise TypeError(\"Unsupported tokenization algorithm detected\")\n","\n","    @staticmethod\n","    def parse_req_body_or_params(line: str):\n","        parsed_line = parse.parse_qs(parse.unquote_plus(string=line))\n","\n","        tokens = []\n","        for k, v in parsed_line.items():\n","            tokens.append(k)\n","            tokens.extend(v)\n","\n","        return tokens\n","\n","    @staticmethod\n","    def load(file_path: str):\n","        return Vocab(tokenizer=Tokenizer.from_file(file_path))"]},{"cell_type":"markdown","metadata":{"id":"LLCCxrOzKdaN"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":223,"status":"ok","timestamp":1714147277590,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"Bi76zAr_JpbV"},"outputs":[],"source":["# Defining global constants\n","RANDOM_SEED = 42\n","BATCH_SIZE = 64\n","\n","torch.manual_seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1714147333947,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"FiQJ39fWKlBI","outputId":"9c02310f-813b-4907-90dd-07072bcf3ac5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device of execution -  cpu\n"]}],"source":["# This is how we select a GPU if it's available on your computer or in the Colab environment.\n","print('Device of execution - ', device)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1501,"status":"ok","timestamp":1714147336703,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"_fsd7PRFKpPT"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","df = pd.read_csv('./dataset.csv')\n","df = CSICDataset.process_df(df)\n","\n","# # The following two lines are used to load the indices of the training and validation sets\n","# train_indices = np.load('./dataset/train_indices.npy')\n","# val_indices = np.load('./dataset/val_indices.npy')\n","\n","# # The following two lines are used to select the training and validation sets from the dataframe based on the indices loaded above\n","# train_data = df.loc[train_indices].reset_index(drop=True)\n","# val_data = df.loc[val_indices].reset_index(drop=True)\n","\n","train_data, val_data = train_test_split(df, test_size=0.2)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":36070,"status":"ok","timestamp":1714147372772,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"u8E1liYAQ9yL"},"outputs":[],"source":["train_dataset = CSICDataset(df=train_data, vocab_size=5000, min_frequency=1, tokenization_algorithm='bpe')\n","train_vocab = train_dataset.vocab\n","\n","val_dataset = CSICDataset(df=val_data, vocab=train_vocab)\n","\n","train_sampler = RandomSampler(train_dataset)\n","val_sampler   = RandomSampler(val_dataset)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1714147372775,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"FbUOjJ8aROv4","outputId":"178be2f8-102f-4138-da81-675783239332"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training and Validation dataset sizes match!\n"]}],"source":["# Check Dataset Lengths\n","assert len(train_dataset) == 45319, \"Training Dataset is of incorrect size\"\n","assert len(val_dataset) == 11330, \"Validation Dataset is of incorrect size\"\n","\n","print('Training and Validation dataset sizes match!')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1714147372776,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"Ihg6xpQtRW5S"},"outputs":[],"source":["PADDING_VALUE = train_vocab.pad_id"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1714147372777,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"uZnYLvVVRYgx"},"outputs":[],"source":["def collate_fn(batch, padding_value=PADDING_VALUE):\n","    # Batch is of the form List[Tuple(Features(tokenized_ids,...), Labels)]\n","    sequences = [torch.tensor(sample[0]['tokenized_ids'], dtype=torch.long, device=device) for sample in batch]\n","    padded_tokens = torch.nn.utils.rnn.pad_sequence(sequences=sequences,batch_first=True, padding_value=padding_value)\n","    attention_mask = (padded_tokens != padding_value).float()\n","    labels = torch.tensor([sample[1] for sample in batch])\n","\n","    return padded_tokens, attention_mask, labels"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1714147372777,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"4BvGc77ARad6"},"outputs":[],"source":["train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n","val_iterator   = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1714147372916,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"HEXLr4d2Rcfw","outputId":"153cc110-9524-42c8-8539-d15392db8a1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tokens: torch.Size([64, 199])\n","atteniton masks: torch.Size([64, 199])\n","labels: torch.Size([64])\n"]}],"source":["for tokens, attention_masks, labels in train_iterator:\n","    print(f'tokens: {tokens.shape}')\n","    print(f'atteniton masks: {attention_masks.shape}')\n","    print(f'labels: {labels.shape}')\n","    break"]},{"cell_type":"markdown","metadata":{"id":"60o3ZPPBSCHu"},"source":["# DistillBERT Model"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":144,"status":"ok","timestamp":1714106275394,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"wewChS1rsTsh"},"outputs":[],"source":["import transformers\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import torch.nn.functional as F\n","# from torchsummary import summary\n","from tqdm import tqdm\n","\n","# add python path to include src directory\n","import sys\n","sys.path.insert(0, '../src')\n","\n","# standard library imports\n","from dataclasses import dataclass\n","from pathlib import Path\n","from typing import Tuple\n","import math\n","\n","# related third party imports\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizer\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import tqdm\n","import time"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":95,"status":"ok","timestamp":1714106317147,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"8Ze9-urxJSk_"},"outputs":[],"source":["class BertTrainer:\n","    \"\"\" A training and evaluation loop for PyTorch models with a BERT like architecture. \"\"\"\n","\n","\n","    def __init__(\n","        self,\n","        model,\n","        train_dataloader,\n","        eval_dataloader=None,\n","        epochs=1,\n","        lr=5e-04,\n","        output_dir='./',\n","        output_filename='model_state_dict.pt',\n","        save=False,\n","        tabular=False,\n","    ):\n","        \"\"\"\n","        Args:\n","            model: torch.nn.Module: = A PyTorch model with a BERT like architecture,\n","            tokenizer: = A BERT tokenizer for tokenizing text input,\n","            train_dataloader: torch.utils.data.DataLoader =\n","                A dataloader containing the training data with \"text\" and \"label\" keys (optionally a \"tabular\" key),\n","            eval_dataloader: torch.utils.data.DataLoader =\n","                A dataloader containing the evaluation data with \"text\" and \"label\" keys (optionally a \"tabular\" key),\n","            epochs: int = An integer representing the number epochs to train,\n","            lr: float = A float representing the learning rate for the optimizer,\n","            output_dir: str = A string representing the directory path to save the model,\n","            output_filename: string = A string representing the name of the file to save in the output directory,\n","            save: bool = A boolean representing whether or not to save the model,\n","            tabular: bool = A boolean representing whether or not the BERT model is modified to accept tabular data,\n","        \"\"\"\n","\n","        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        self.model = model.to(self.device)\n","        self.train_dataloader = train_dataloader\n","        self.eval_dataloader = eval_dataloader\n","        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr)\n","        self.loss_fn = nn.CrossEntropyLoss()\n","        self.output_dir = output_dir\n","        self.output_filename = output_filename\n","        self.save = save\n","        self.eval_loss = float('inf')  # tracks the lowest loss so as to only save the best model\n","        self.epochs = epochs\n","        self.epoch_best_model = 0  # tracks which epoch the lowest loss is in so as to only save the best model\n","        self.tabular = tabular\n","\n","    def train(self, evaluate=False):\n","        \"\"\" Calls the batch iterator to train and optionally evaluate the model.\"\"\"\n","        for epoch in range(self.epochs):\n","            self.iteration(epoch, self.train_dataloader)\n","            if evaluate and self.eval_dataloader is not None:\n","                self.iteration(epoch, self.eval_dataloader, train=False)\n","\n","    def evaluate(self):\n","        \"\"\" Calls the batch iterator to evaluate the model.\"\"\"\n","        epoch=0\n","        self.iteration(epoch, self.eval_dataloader, train=False)\n","\n","    def iteration(self, epoch, data_loader, train=True):\n","        \"\"\" Iterates through one epoch of training or evaluation\"\"\"\n","\n","        # initialize variables\n","        loss_accumulated = 0.\n","        correct_accumulated = 0\n","        samples_accumulated = 0\n","        preds_all = []\n","        labels_all = []\n","\n","        self.model.train() if train else self.model.eval()\n","\n","        # progress bar\n","        mode = \"train\" if train else \"eval\"\n","        batch_iter = tqdm.tqdm(\n","            enumerate(data_loader),\n","            desc=f\"EP ({mode}) {epoch}\",\n","            total=len(data_loader),\n","            bar_format=\"{l_bar}{r_bar}\"\n","        )\n","\n","        total_comp_time = 0\n","        # iterate through batches of the dataset\n","        for i, batch in batch_iter:\n","            # print(\"Batch: \", batch)\n","            # print(len(batch))\n","            # tokenize data\n","            # batch_t = self.tokenizer(\n","            #     batch[0],\n","            #     padding='max_length',\n","            #     max_length=512,\n","            #     truncation=True,\n","            #     return_tensors='pt',\n","            # )\n","            # batch_t = {key: value.to(self.device) for key, value in batch_t.items()}\n","            # batch_t[\"input_labels\"] = batch[\"label\"].to(self.device)\n","            # batch_t[\"tabular_vectors\"] = batch[\"tabular\"].to(self.device)\n","            # batch = {key: value.to(self.device) for key, value in batch.items()}\n","            # token_types = torch.zeros((len(batch[0][0])), dtype=torch.long).to(self.device)\n","            # forward pass - include tabular data if it is a tabular model\n","\n","            start = time.time()\n","            logits = self.model(\n","                input_ids=batch[0],\n","                attention_mask=batch[1],\n","            ).logits\n","            total_comp_time += time.time() - start\n","\n","            # calculate loss\n","            labels = batch[2].to(self.device)\n","            loss = self.loss_fn(logits, labels)\n","\n","            # compute gradient and and update weights\n","            if train:\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","\n","            # calculate the number of correct predictions\n","            preds = logits.argmax(dim=-1)\n","            correct = preds.eq(labels).sum().item()\n","\n","            # accumulate batch metrics and outputs\n","            loss_accumulated += loss.item()\n","            correct_accumulated += correct\n","            samples_accumulated += len(batch[2])\n","            preds_all.append(preds.detach())\n","            labels_all.append(labels.detach())\n","\n","\n","        average_comp_time = total_comp_time / len(batch_iter)\n","        print(\"Average Comp Time: \", average_comp_time)\n","\n","        # concatenate all batch tensors into one tensor and move to cpu for compatibility with sklearn metrics\n","        preds_all = torch.cat(preds_all, dim=0).cpu()\n","        labels_all = torch.cat(labels_all, dim=0).cpu()\n","\n","        # metrics\n","        accuracy = accuracy_score(labels_all, preds_all)\n","        precision = precision_score(labels_all, preds_all, average='macro')\n","        recall = recall_score(labels_all, preds_all, average='macro')\n","        f1 = f1_score(labels_all, preds_all, average='macro')\n","        avg_loss_epoch = loss_accumulated / len(data_loader)\n","\n","        # print metrics to console\n","        print(\n","            f\"samples={samples_accumulated}, \\\n","            correct={correct_accumulated}, \\\n","            acc={round(accuracy, 4)}, \\\n","            recall={round(recall, 4)}, \\\n","            prec={round(precision,4)}, \\\n","            f1={round(f1, 4)}, \\\n","            loss={round(avg_loss_epoch, 4)}\"\n","        )\n","\n","        # save the model if the evaluation loss is lower than the previous best epoch\n","        if self.save and not train and avg_loss_epoch < self.eval_loss:\n","\n","            # create directory and filepaths\n","            dir_path = Path(self.output_dir)\n","            dir_path.mkdir(parents=True, exist_ok=True)\n","            file_path = dir_path / f\"{self.output_filename}_epoch_{epoch}.pt\"\n","\n","            # delete previous best model from hard drive\n","            if epoch > 0:\n","                file_path_best_model = dir_path / f\"{self.output_filename}_epoch_{self.epoch_best_model}.pt\"\n","                !rm -f $file_path_best_model\n","\n","            # save model\n","            torch.save({\n","                'model_state_dict': self.model.state_dict(),\n","                'optimizer_state_dict': self.optimizer.state_dict()\n","            }, file_path)\n","\n","            # update the new best loss and epoch\n","            self.eval_loss = avg_loss_epoch\n","            self.epoch_best_model = epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489,"referenced_widgets":["a72ab139a6bd4ab2809234e474d5f152","80f5256b52c64b4ea92cacd6606fab41","77b4202ef04748198512d8280a0ad47b","2380f3bc1a574e219879aa0481ce9efa","45efba8e87c7464d9a2c9b6270e9ec12","b925f9c8aabb4bfe83b0667e01199e3e","6ee8e67f18ac410992729ea96958d231","e5b3e2eac054492eb167431a6ae9f0a1","8a38f5a1247044a990d8754c518c5cf9","5dbc68ba87694ae1bf51646c20e07399","01edf579c92a492f8bb9fb289e933243","80aabb350b6f4a28bdc08fb75885304f","bf215510974e4aef94cec87b62a644d1","ffa5c4925a024ddc9e747d58992fb547","99db0227906342ecad3a14442e3a5d79","fda2f3d5ab4046c1adb693d30fe8e88b","641b54b96042437d8b32c50da0244cde","ce5eacc4604c402ca1e7e7db1271eaa5","772d4f1a97584e01b1d289d7ecd4b802","ed2752314b3d41a7969a0b2cb15de139","ac237e85301249819f01c35f5ada4df0","1d6bc8a9fb8b44f78c85baa235be0149"]},"executionInfo":{"elapsed":4701,"status":"error","timestamp":1714147401848,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"_ZAnZmt-D3tq","outputId":"7e979c49-36fe-4572-bdc9-1cbc4c18c69d"},"outputs":[],"source":["from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","import time\n","\n","# Load the DistilBERT tokenizer and model\n","# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvCnWqqYKCp3","outputId":"078391c4-628a-48b1-c3b1-055759f84788"},"outputs":[{"name":"stderr","output_type":"stream","text":["EP (train) 0: 100%|| 1417/1417 [38:10<00:00,  1.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Comp Time:  0.5582960563893881\n","samples=45319,             correct=25637,             acc=0.5657,             recall=0.5,             prec=0.5,             f1=0.3736,             loss=0.6872\n"]},{"name":"stderr","output_type":"stream","text":["EP (eval) 0: 100%|| 355/355 [03:26<00:00,  1.72it/s]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Average Comp Time:  0.47950864106836455\n","samples=11330,             correct=6441,             acc=0.5685,             recall=0.5,             prec=0.2842,             f1=0.3624,             loss=0.6853\n"]},{"name":"stderr","output_type":"stream","text":["EP (train) 1: 100%|| 1417/1417 [39:49<00:00,  1.69s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Comp Time:  0.5635541629522051\n","samples=45319,             correct=25709,             acc=0.5673,             recall=0.5002,             prec=0.5124,             f1=0.3649,             loss=0.6844\n"]},{"name":"stderr","output_type":"stream","text":["EP (eval) 1: 100%|| 355/355 [03:31<00:00,  1.68it/s]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Average Comp Time:  0.4942598383191606\n","samples=11330,             correct=6441,             acc=0.5685,             recall=0.5,             prec=0.2842,             f1=0.3624,             loss=0.6838\n"]},{"name":"stderr","output_type":"stream","text":["EP (train) 2: 100%|| 1417/1417 [42:25<00:00,  1.80s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Comp Time:  0.5809059459387457\n","samples=45319,             correct=25704,             acc=0.5672,             recall=0.5001,             prec=0.5074,             f1=0.3653,             loss=0.6854\n"]},{"name":"stderr","output_type":"stream","text":["EP (eval) 2: 100%|| 355/355 [03:22<00:00,  1.76it/s]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Average Comp Time:  0.47213033958220146\n","samples=11330,             correct=6441,             acc=0.5685,             recall=0.5,             prec=0.2842,             f1=0.3624,             loss=0.6838\n"]},{"name":"stderr","output_type":"stream","text":["EP (train) 3:  51%|| 721/1417 [19:00<20:04,  1.73s/it]"]}],"source":["trainer_distill_bert = BertTrainer(\n","    model,\n","    lr=0.001,\n","    epochs=10,\n","    train_dataloader=train_iterator,\n","    eval_dataloader=val_iterator,\n","    output_dir='../models/distill_bert',\n","    output_filename='distill_bert',\n","    save=True,\n",")\n","\n","trainer_distill_bert.train(evaluate=True)\n","\n","# Define a function to preprocess the input text\n","# def preprocess(text):\n","#     encoding = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n","#     return encoding\n","\n","# Example usage\n","# text = \"This movie was absolutely fantastic! I loved every minute of it.\"\n","\n","# # Preprocess the input text\n","# encoding = preprocess(text)\n","\n","# Pass the input through the DistilBERT model\n","\n","\n","\n","\n","# output = model(**encoding)\n","\n","# # Get the predicted class label\n","# predicted_label = output.logits.argmax(-1).item()\n","\n","# print(f\"Predicted class label: {predicted_label}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["30e59f5fdcc143e38e306519039376d7","9492a738426d4e5782a52d04f766f01f","1119fb85e7f849a3a953c7751d09dfc4","3262b4b01ba74dc78da30a362a728783","cc77a159e19047eb89017d3fdcc80ff6","f7d72e5034f74dc28903686e3e565655","5ba94692f4424e2b9ff83ee0a9628998","b5326c0129d049e7ac503a9b55ee6eb2","b1c841a830c047b6913ac3d16f12ae0b","2a97904a48e0462ea757bb629a05af74","73a81e548e054ac983bb451b9702a92c"]},"executionInfo":{"elapsed":1973,"status":"ok","timestamp":1714147406339,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"OUA0O8FNBN5x","outputId":"00026e43-3964-48cf-abf8-8cd4458f034a"},"outputs":[],"source":["import torch\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","import time\n","\n","# Load the DistilBERT tokenizer and model\n","# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"elapsed":128,"status":"error","timestamp":1714147412121,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"fGsBj3hGB1AH","outputId":"1fb858fb-0aa0-498b-bbf7-70fb48e7ec29"},"outputs":[],"source":["checkpoint = torch.load('distill_bert_epoch_1.pt')\n","model.load_state_dict(checkpoint['model_state_dict'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1714147406512,"user":{"displayName":"shri k","userId":"15567215191369524414"},"user_tz":240},"id":"4YTVZO0UFOJc"},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Lj0wiydF1qs","outputId":"24319737-c4b8-48c9-f01d-aa85899786e0"},"outputs":[],"source":["total_comp_time = 0\n","count = 0\n","for tokens, attention_masks, labels in val_iterator:\n","    print(f'tokens: {tokens.shape}')\n","    print(f'atteniton masks: {attention_masks.shape}')\n","    print(f'labels: {labels.shape}')\n","    start = time.time()\n","    output = model(tokens)\n","    total_comp_time += time.time() - start\n","    count += 1\n","print(count)\n","print(len(val_iterator))\n","print(\"Average Time: \", total_comp_time/len(val_iterator))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ypb2HtawFQft"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01edf579c92a492f8bb9fb289e933243":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1119fb85e7f849a3a953c7751d09dfc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5326c0129d049e7ac503a9b55ee6eb2","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1c841a830c047b6913ac3d16f12ae0b","value":267954768}},"1d6bc8a9fb8b44f78c85baa235be0149":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2380f3bc1a574e219879aa0481ce9efa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dbc68ba87694ae1bf51646c20e07399","placeholder":"​","style":"IPY_MODEL_01edf579c92a492f8bb9fb289e933243","value":" 483/483 [00:00&lt;00:00, 16.1kB/s]"}},"2a97904a48e0462ea757bb629a05af74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30e59f5fdcc143e38e306519039376d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9492a738426d4e5782a52d04f766f01f","IPY_MODEL_1119fb85e7f849a3a953c7751d09dfc4","IPY_MODEL_3262b4b01ba74dc78da30a362a728783"],"layout":"IPY_MODEL_cc77a159e19047eb89017d3fdcc80ff6"}},"3262b4b01ba74dc78da30a362a728783":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a97904a48e0462ea757bb629a05af74","placeholder":"​","style":"IPY_MODEL_73a81e548e054ac983bb451b9702a92c","value":" 268M/268M [00:01&lt;00:00, 198MB/s]"}},"45efba8e87c7464d9a2c9b6270e9ec12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ba94692f4424e2b9ff83ee0a9628998":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dbc68ba87694ae1bf51646c20e07399":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"641b54b96042437d8b32c50da0244cde":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ee8e67f18ac410992729ea96958d231":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73a81e548e054ac983bb451b9702a92c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"772d4f1a97584e01b1d289d7ecd4b802":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77b4202ef04748198512d8280a0ad47b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5b3e2eac054492eb167431a6ae9f0a1","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a38f5a1247044a990d8754c518c5cf9","value":483}},"80aabb350b6f4a28bdc08fb75885304f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf215510974e4aef94cec87b62a644d1","IPY_MODEL_ffa5c4925a024ddc9e747d58992fb547","IPY_MODEL_99db0227906342ecad3a14442e3a5d79"],"layout":"IPY_MODEL_fda2f3d5ab4046c1adb693d30fe8e88b"}},"80f5256b52c64b4ea92cacd6606fab41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b925f9c8aabb4bfe83b0667e01199e3e","placeholder":"​","style":"IPY_MODEL_6ee8e67f18ac410992729ea96958d231","value":"config.json: 100%"}},"8a38f5a1247044a990d8754c518c5cf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9492a738426d4e5782a52d04f766f01f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7d72e5034f74dc28903686e3e565655","placeholder":"​","style":"IPY_MODEL_5ba94692f4424e2b9ff83ee0a9628998","value":"model.safetensors: 100%"}},"99db0227906342ecad3a14442e3a5d79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac237e85301249819f01c35f5ada4df0","placeholder":"​","style":"IPY_MODEL_1d6bc8a9fb8b44f78c85baa235be0149","value":" 147M/268M [00:00&lt;00:00, 314MB/s]"}},"a72ab139a6bd4ab2809234e474d5f152":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80f5256b52c64b4ea92cacd6606fab41","IPY_MODEL_77b4202ef04748198512d8280a0ad47b","IPY_MODEL_2380f3bc1a574e219879aa0481ce9efa"],"layout":"IPY_MODEL_45efba8e87c7464d9a2c9b6270e9ec12"}},"ac237e85301249819f01c35f5ada4df0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1c841a830c047b6913ac3d16f12ae0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5326c0129d049e7ac503a9b55ee6eb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b925f9c8aabb4bfe83b0667e01199e3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf215510974e4aef94cec87b62a644d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_641b54b96042437d8b32c50da0244cde","placeholder":"​","style":"IPY_MODEL_ce5eacc4604c402ca1e7e7db1271eaa5","value":"model.safetensors:  55%"}},"cc77a159e19047eb89017d3fdcc80ff6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce5eacc4604c402ca1e7e7db1271eaa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5b3e2eac054492eb167431a6ae9f0a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed2752314b3d41a7969a0b2cb15de139":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7d72e5034f74dc28903686e3e565655":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fda2f3d5ab4046c1adb693d30fe8e88b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffa5c4925a024ddc9e747d58992fb547":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_772d4f1a97584e01b1d289d7ecd4b802","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed2752314b3d41a7969a0b2cb15de139","value":146800640}}}}},"nbformat":4,"nbformat_minor":0}
